import os
from pathlib import Path
from typing import Optional
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, Document
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.node_parser import SentenceSplitter
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.llms.openai import OpenAI
from config.settings import Settings as AppSettings

class RAGEngine:
    """LlamaIndexã‚’ä½¿ç”¨ã—ãŸå®Œå…¨ãªRAGã‚·ã‚¹ãƒ†ãƒ ï¼ˆæ¤œç´¢ + ç”Ÿæˆï¼‰"""
    
    def __init__(self):
        """RAGã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆæœŸåŒ–"""
        self.index: Optional[VectorStoreIndex] = None
        self.query_engine: Optional[RetrieverQueryEngine] = None
        self.node_parser: Optional[SentenceSplitter] = None
        self._setup_llama_index()
    
    def _setup_llama_index(self):
        """LlamaIndexã®è¨­å®šã‚’åˆæœŸåŒ–ï¼ˆRAGå°‚ç”¨ã®LLMè¨­å®šï¼‰"""
        # RAGç”¨LLMè¨­å®š - OpenRouterçµŒç”±
        Settings.llm = OpenAI(
            api_key=AppSettings.OPENROUTER_API_KEY,
            api_base=AppSettings.OPENROUTER_BASE_URL,
            model="gpt-4o-mini",  # OpenRouterçµŒç”±ã§ã‚‚OpenAIå½¢å¼ã®ãƒ¢ãƒ‡ãƒ«åã‚’ä½¿ç”¨
            temperature=0.2,  # RAGã§ã¯äº‹å®Ÿãƒ™ãƒ¼ã‚¹ãªã®ã§ä½ã„æ¸©åº¦
            system_prompt="ã‚ãªãŸã¯æä¾›ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã«åŸºã¥ã„ã¦ã€æ­£ç¢ºã§è©³ç´°ãªå›ç­”ã‚’æä¾›ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ›¸ã‹ã‚Œã¦ã„ãªã„æƒ…å ±ã«ã¤ã„ã¦ã¯æ¨æ¸¬ã›ãšã€æ˜ç¢ºã«ã€Œãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€ã¨ä¼ãˆã¦ãã ã•ã„ã€‚"
        )
        
        # OpenAI Embeddingsã®è¨­å®šï¼ˆOpenRouterçµŒç”±ï¼‰
        Settings.embed_model = OpenAIEmbedding(
            api_key=AppSettings.OPENROUTER_API_KEY,
            api_base=AppSettings.OPENROUTER_BASE_URL,
            model="text-embedding-3-small"
        )
        
        # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®è¨­å®šï¼ˆæ—¥è¨˜ã«æœ€é©åŒ–ï¼‰
        self.node_parser = SentenceSplitter(
            chunk_size=512,  # æ—¥è¨˜ã®æ®µè½ç¨‹åº¦ã®ã‚µã‚¤ã‚º
            chunk_overlap=50,  # æ–‡è„ˆä¿æŒã®ãŸã‚ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—
            separator="\n\n",  # æ®µè½åŒºåˆ‡ã‚Šã‚’å„ªå…ˆ
        )
        Settings.node_parser = self.node_parser
    
    def load_documents(self) -> bool:
        """æ—¥è¨˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãï¼‰"""
        try:
            print("ğŸ“– Obsidianãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...")
            
            # Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’èª­ã¿è¾¼ã¿
            reader = SimpleDirectoryReader(
                input_dir=AppSettings.DIARY_PATH,
                required_exts=[".md"],
                recursive=True
            )
            
            raw_documents = reader.load_data()
            
            if not raw_documents:
                print(f"è­¦å‘Š: {AppSettings.DIARY_PATH} ã«Markdownãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False
            
            print(f"ğŸ“„ èª­ã¿è¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(raw_documents)}")
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å¼·åŒ–
            enhanced_documents = []
            for doc in raw_documents:
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ–‡æ›¸åã‚’æŠ½å‡º
                file_path = Path(doc.metadata.get('file_path', ''))
                doc_name = file_path.stem
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«æ–‡æ›¸æƒ…å ±ã‚’è¿½åŠ 
                doc.metadata.update({
                    'document_name': doc_name,
                    'source_file': file_path.name,
                    'content_type': 'Obsidianæ–‡æ›¸'
                })
                
                enhanced_documents.append(doc)
            
            print(f"ğŸ“Š ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å¼·åŒ–å®Œäº†: {len(enhanced_documents)}ä»¶")
            
            # ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ï¼ˆæ”¹è‰¯ã•ã‚ŒãŸãƒãƒ£ãƒ³ã‚¯è¨­å®šã§ï¼‰
            print("ğŸ”— ãƒ™ã‚¯ãƒˆãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­...")
            self.index = VectorStoreIndex.from_documents(
                enhanced_documents,
                node_parser=self.node_parser,
                show_progress=False
            )
            
            # ã‚¯ã‚¨ãƒªã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆï¼ˆRAGç‰¹åŒ–è¨­å®šï¼‰
            self.query_engine = self.index.as_query_engine(
                similarity_top_k=8,  # ã‚ˆã‚Šå¤šãã®é–¢é€£æ–‡æ›¸ã‚’æ¤œç´¢
                response_mode="tree_summarize",  # è¤‡æ•°æ–‡æ›¸ã‚’åŠ¹ç‡çš„ã«è¦ç´„
                verbose=False,  # æœ¬ç•ªç”¨ã¯false
                node_postprocessors=[],  # å¿…è¦ã«å¿œã˜ã¦å¾Œå‡¦ç†ã‚’è¿½åŠ 
            )
            
            print("âœ… RAGã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")
            print(f"ğŸ“ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–ã•ã‚ŒãŸãƒãƒ¼ãƒ‰æ•°: {len(self.index.docstore.docs)}")
            return True
            
        except Exception as e:
            print(f"ã‚¨ãƒ©ãƒ¼: æ—¥è¨˜ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ - {str(e)}")
            return False
    
    def answer_with_rag(self, query: str) -> str:
        """LlamaIndexã«ã‚ˆã‚‹å®Œå…¨ãªRAGå‡¦ç†ï¼ˆæ¤œç´¢ + ç”Ÿæˆï¼‰"""
        if not self.query_engine:
            return "ã‚¨ãƒ©ãƒ¼: RAGã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        try:
            print(f"ğŸ” RAGå‡¦ç†é–‹å§‹: {query}")
            
            # LlamaIndexãŒãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã¨å›ç­”ç”Ÿæˆã‚’ä¸€æ‹¬å‡¦ç†
            enhanced_query = f"""
            Obsidianã®çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ä»¥ä¸‹ã®è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

            è³ªå•: {query}

            å›ç­”ã®éš›ã¯ä»¥ä¸‹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ï¼š
            - é–¢é€£ã™ã‚‹æ–‡æ›¸åãŒã‚ã‚Œã°æ˜è¨˜ã™ã‚‹
            - å…·ä½“çš„ãªå†…å®¹ã‚„è©³ç´°ã‚’å«ã‚ã‚‹
            - è¤‡æ•°ã®æ–‡æ›¸ã«ã¾ãŸãŒã‚‹æƒ…å ±ãŒã‚ã‚Œã°çµ±åˆã—ã¦å›ç­”ã™ã‚‹
            - ã‚½ãƒ¼ã‚¹ã¨ãªã‚‹æ–‡æ›¸åã‚’å¯èƒ½ãªé™ã‚Šç¤ºã™
            - ä¼šç¤¾ã®æ¥­å‹™ã‚„çµŒå–¶ã«é–¢ã™ã‚‹æƒ…å ±ã¨ã—ã¦é©åˆ‡ã«ã¾ã¨ã‚ã‚‹
            """
            
            response = self.query_engine.query(enhanced_query)
            
            print("âœ… RAGå‡¦ç†å®Œäº†")
            return str(response)
            
        except Exception as e:
            return f"RAGå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}"
    
    def get_retrieval_info(self, query: str) -> dict:
        """æ¤œç´¢ã§ãƒ’ãƒƒãƒˆã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’å–å¾—ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰"""
        if not self.query_engine:
            return {"error": "RAGã‚¨ãƒ³ã‚¸ãƒ³ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"}
        
        try:
            # Retrieverã‚’ç›´æ¥ä½¿ã£ã¦æ¤œç´¢æƒ…å ±ã‚’å–å¾—
            retriever = self.index.as_retriever(similarity_top_k=3)
            nodes = retriever.retrieve(query)
            
            result = {
                "query": query,
                "retrieved_count": len(nodes),
                "sources": []
            }
            
            for i, node in enumerate(nodes):
                source_info = {
                    "rank": i + 1,
                    "score": node.score,
                    "document_name": node.metadata.get('document_name', 'ä¸æ˜'),
                    "source_file": node.metadata.get('source_file', 'ä¸æ˜'),
                    "content_preview": node.text[:100] + "..." if len(node.text) > 100 else node.text
                }
                result["sources"].append(source_info)
            
            return result
            
        except Exception as e:
            return {"error": f"æ¤œç´¢æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}"}
    
    def is_ready(self) -> bool:
        """RAGã‚¨ãƒ³ã‚¸ãƒ³ãŒä½¿ç”¨å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯"""
        return self.query_engine is not None